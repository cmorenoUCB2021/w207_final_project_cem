{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "# import xlsxwriter\n",
    "import openpyxl\n",
    "import os.path\n",
    "from os.path import exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"../data/train.csv\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale10(n):\n",
    "    val = 0\n",
    "    if n <=10: \n",
    "        val = 1\n",
    "    elif n >10 and n<=20:\n",
    "        val = 2\n",
    "    elif n >20 and n <=30:\n",
    "        val = 3\n",
    "    elif n>30 and n <=40:\n",
    "        val = 4\n",
    "    elif n > 40 and n<=50:\n",
    "        val = 5\n",
    "    elif n>50 and n<=60:\n",
    "        val = 6\n",
    "    elif n>60 and n<=70:\n",
    "        val = 7\n",
    "    elif n>70 and n<=80:\n",
    "        val = 8\n",
    "    elif n>80 and n<=90:\n",
    "        val = 9\n",
    "    else: \n",
    "        val = 10\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale5(n):\n",
    "    val = 0\n",
    "    if n <=20: \n",
    "        val = 1\n",
    "    elif n >20 and n<=40:\n",
    "        val = 2\n",
    "    elif n >40 and n <=60:\n",
    "        val = 3\n",
    "    elif n>60 and n <=80:\n",
    "        val = 4\n",
    "    else: val = 5\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale4(n):\n",
    "    val = 0\n",
    "    if n <=25: \n",
    "        val = 1\n",
    "    elif n >25 and n<=50:\n",
    "        val = 2\n",
    "    elif n >50 and n <=75:\n",
    "        val = 3\n",
    "    else: \n",
    "        val = 4\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale3(n):\n",
    "    val = 0\n",
    "    if n <=34: \n",
    "        val = 1\n",
    "    elif n >34 and n<=68:\n",
    "        val = 2\n",
    "    else:\n",
    "        val = 3\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale2(n):\n",
    "    val = 0\n",
    "    if n <=50: \n",
    "        val = 1\n",
    "    else:\n",
    "        val = 2\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale10\"] = df_data.apply(lambda row: scale10(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale5\"] = df_data.apply(lambda row: scale5(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale4\"] = df_data.apply(lambda row: scale4(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale3\"] = df_data.apply(lambda row: scale3(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"Scale2\"] = df_data.apply(lambda row: scale2(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsL = df_data.columns\n",
    "columnsL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X and Y data - shuffle data.\n",
    "X_cols = ['Subject Focus','Eyes', 'Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur',]\n",
    "X = np.array(df_data[X_cols])\n",
    "Y = df_data['Pawpularity'].values[:]\n",
    "\n",
    "id_image = df_data['Id'].values[:]\n",
    "\n",
    "Y10 = df_data['Scale10'].values[:]\n",
    "Y5 = df_data['Scale5'].values[:]\n",
    "Y4 = df_data['Scale4'].values[:]\n",
    "Y3 = df_data['Scale3'].values[:]\n",
    "Y2 = df_data['Scale2'].values[:]\n",
    "\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y, id_image = X[shuffle], Y[shuffle], id_image[shuffle]\n",
    "Y10, Y5, Y4, Y3, Y2 = Y10[shuffle], Y5[shuffle], Y4[shuffle], Y3[shuffle], Y2[shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sizes for train, development and test data (0.5, 0.2, 0.3)\n",
    "per_train = 0.5\n",
    "per_dev = 0.2\n",
    "\n",
    "num_images = len(Y)\n",
    "train_size = int(round(num_images * per_train,0))\n",
    "dev_size = int(round(num_images * per_dev,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data based on defined sizes\n",
    "test_data, test_labels, id_test = X[train_size+dev_size:], Y[train_size+dev_size:], id_image[train_size+dev_size:]\n",
    "test_y10 = Y10[train_size+dev_size:]\n",
    "test_y5 = Y5[train_size+dev_size:]\n",
    "test_y4 = Y4[train_size+dev_size:]\n",
    "test_y3 = Y3[train_size+dev_size:]\n",
    "test_y2 = Y2[train_size+dev_size:]\n",
    "\n",
    "dev_data, dev_labels, id_dev = X[train_size:train_size+dev_size], Y[train_size:train_size+dev_size], id_image[train_size:train_size+dev_size]\n",
    "dev_y10 = Y10[train_size:train_size+dev_size]\n",
    "dev_y5 = Y5[train_size:train_size+dev_size]\n",
    "dev_y4 = Y4[train_size:train_size+dev_size]\n",
    "dev_y3 = Y3[train_size:train_size+dev_size]\n",
    "dev_y2 = Y2[train_size:train_size+dev_size]\n",
    "\n",
    "train_data, train_labels, id_train = X[:train_size], Y[:train_size], id_image[:train_size]\n",
    "train_y10 =  Y10[:train_size]\n",
    "train_y5 =  Y5[:train_size]\n",
    "train_y4 =  Y4[:train_size]\n",
    "train_y3 =  Y3[:train_size]\n",
    "train_y2 =  Y2[:train_size]\n",
    "\n",
    "print(num_images)\n",
    "print(train_data.shape, train_labels.shape, id_train.shape)\n",
    "print(dev_data.shape, dev_labels.shape, id_dev.shape)\n",
    "print(test_data.shape, test_labels.shape, id_test.shape)\n",
    "print(test_y10.shape, dev_y10.shape, train_y10.shape)\n",
    "print(test_y5.shape, dev_y5.shape, train_y5.shape)\n",
    "print(test_y4.shape, dev_y4.shape, train_y4.shape)\n",
    "print(test_y3.shape, dev_y3.shape, train_y3.shape)\n",
    "print(test_y2.shape, dev_y2.shape, train_y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrt_excel(file, sheet_name, df):\n",
    "    if os.path.exists(file):\n",
    "        with pd.ExcelWriter(file, engine=\"openpyxl\", mode='a') as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)\n",
    "    else:\n",
    "        with pd.ExcelWriter(file, engine=\"openpyxl\") as writer:\n",
    "            df.to_excel(writer, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = []\n",
    "rmse = []\n",
    "acc = []\n",
    "hamm = []\n",
    "\n",
    "knn_mod = KNeighborsClassifier(n_neighbors=2, algorithm=\"auto\", weights=\"uniform\", p=1)\n",
    "knn_mod.fit(train_data, train_labels)\n",
    "acc.append(knn_mod.score(dev_data, dev_labels))\n",
    "f1_score.append(metrics.f1_score(dev_labels, knn_mod.predict(dev_data), average=\"weighted\"))\n",
    "rmse.append(metrics.mean_squared_error(dev_labels, knn_mod.predict(dev_data), squared=False))\n",
    "hamm.append(metrics.hamming_loss(dev_labels, knn_mod.predict(dev_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(train_data, train_labels, dev_data, dev_labels, algorithm, weigth, klist):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for k in klist:\n",
    "        knn_mod = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm, weights=weigth, p=1)\n",
    "        knn_mod.fit(train_data, train_labels)\n",
    "        acc.append(knn_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, knn_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, knn_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, knn_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "    \n",
    "def knn_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_knn = pd.DataFrame()\n",
    "    klist = [1, 2, 3, 4, 5, 6, 7,8,9, 10, 11, 12, 13, 14, 15]\n",
    "    algorithm_list = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "   \n",
    "    weights = [\"uniform\", \"distance\"]\n",
    "    df_knn[\"K\"] = klist\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_knn[algorithm+\"_f1\"], df_knn[algorithm+\"_rmse\"], df_knn[algorithm+\"_acc\"], df_knn[algorithm+\"_hamm\"]  = knn_model(train_data, Y_train, dev_data, Y_dev, algorithm, weights[1], klist)\n",
    "        \n",
    "    print(df_knn)\n",
    "    print(\"df_knn\")\n",
    "    return(df_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for alpha in alpha_list:\n",
    "        NB_mod = BernoulliNB(alpha=alpha)\n",
    "        NB_mod.fit(train_data, train_labels)\n",
    "        acc.append(NB_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, NB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, NB_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, NB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def NB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_NB = pd.DataFrame()\n",
    "    df_NB[\"Alpha\"] = alpha_list\n",
    "    df_NB[\"F1_score\"], df_NB[\"RMSE\"], df_NB[\"ACC\"], df_NB[\"HAMM\"] = NB_model(train_data, Y_train, dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_NB)\n",
    "    print(\"df_NB\")\n",
    "    return(df_NB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for alpha in alpha_list:\n",
    "        MNB_mod = MultinomialNB(alpha=alpha)\n",
    "        MNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, MNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, MNB_mod.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, MNB_mod.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, MNB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def MNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_MNB = pd.DataFrame()\n",
    "    df_MNB[\"Alpha\"] = alpha_list\n",
    "    df_MNB[\"F1_score\"], df_MNB[\"RMSE\"], df_MNB[\"ACC\"], df_MNB[\"HAMM\"] = MNB_model(train_data, Y_train, \n",
    "                                                                                  dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_MNB)\n",
    "    print(\"df_MNB\")\n",
    "    return(df_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB (only classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNB_model(train_data, train_labels, dev_data, dev_labels, smoothing_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for var_smoothing in smoothing_list:\n",
    "        GNB_mod = GaussianNB(var_smoothing=var_smoothing)\n",
    "        GNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, GNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, GNB_mod.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, GNB_mod.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, GNB_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def GNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    smoothing_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_GNB = pd.DataFrame()\n",
    "    df_GNB[\"Var Smooth\"] = smoothing_list\n",
    "    df_GNB[\"F1_score\"], df_GNB[\"RMSE\"], df_GNB[\"ACC\"], df_GNB[\"HAMM\"] = GNB_model(train_data, Y_train, dev_data, Y_dev, smoothing_list)\n",
    "\n",
    "    print(df_GNB)\n",
    "    print(\"df_GNB\")\n",
    "    return(df_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "Warning The choice of the algorithm depends on the penalty chosen: Supported penalties by solver:  \n",
    "- ‘newton-cg’ - [‘l2’, ‘none’]  \n",
    "- ‘lbfgs’ - [‘l2’, ‘none’]  \n",
    "- ‘liblinear’ - [‘l1’, ‘l2’]  \n",
    "- ‘sag’ - [‘l2’, ‘none’]  \n",
    "- ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, ‘none’]\n",
    "\n",
    "**max_iter was increased to 200, so it would converge**\n",
    "- max_iter int, default=100\n",
    "- Maximum number of iterations taken for the solvers to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogR_model(train_data, train_labels, dev_data, dev_labels, penalty, solver, c_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for c in c_list:\n",
    "        logR_mod = LogisticRegression(C=c, solver=solver, multi_class=\"auto\", penalty=penalty, max_iter=200)\n",
    "        logR_mod.fit(train_data, train_labels)\n",
    "        acc.append(logR_mod.score(dev_data, dev_labels))\n",
    "        f1_score.append(metrics.f1_score(dev_labels, logR_mod.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, logR_mod.predict(dev_data), squared=False))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, logR_mod.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def LogR_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_logR =pd.DataFrame()\n",
    "    solver_list = [\"liblinear\", \"newton-cg\", \"sag\", \"lbfgs\"]\n",
    "    c_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "    df_logR[\"C\"] = c_list\n",
    "    for solver in solver_list:\n",
    "#         df_logR[solver] = LogR_model(train_data, Y_train, dev_data, Y_dev, \"l2\", solver, c_list)\n",
    "        df_logR[solver+\"_f1\"], df_logR[solver+\"_rmse\"], df_logR[solver+\"_acc\"], df_logR[solver+\"_hamm\"]= LogR_model(train_data, Y_train, dev_data, Y_dev, \"l2\", solver, c_list)\n",
    "\n",
    "    print(df_logR)\n",
    "    print(\"df_LogR\")\n",
    "    return(df_logR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree (Regression) - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_model(train_data, train_labels, dev_data, dev_labels, criterion, max_depth_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for max_depth in max_depth_list:\n",
    "        dt_model = DecisionTreeClassifier(criterion=criterion, min_samples_split=10, max_depth=max_depth)\n",
    "#         dt_model = DecisionTreeRegressor(criterion=criterion, min_samples_split=10, max_depth=max_depth)\n",
    "        dt_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, dt_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, dt_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, dt_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, dt_model.predict(dev_data)))       \n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def DT_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_DT =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    max_depth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    df_DT[\"max_depth\"] = max_depth_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "#         df_DT[criterion] = DT_model(train_data, Y_train, dev_data, Y_dev, criterion, max_depth_list)\n",
    "        df_DT[criterion+\"_f1\"], df_DT[criterion+\"_rmse\"], df_DT[criterion+\"_acc\"], df_DT[criterion+\"_hamm\"]= DT_model(train_data, \n",
    "                                                                                                                      Y_train, dev_data, \n",
    "                                                                                                                      Y_dev, criterion, max_depth_list)\n",
    "\n",
    "    print(df_DT)\n",
    "    print(\"df_DT\")\n",
    "    return(df_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(train_data, train_labels, dev_data, dev_labels, criterion, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        RF_model = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion, min_samples_split=10)\n",
    "        RF_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, RF_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, RF_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, RF_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, RF_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def RF_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_RF =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_RF[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "#         df_RF[criterion] = RF_model(train_data, Y_train, dev_data, Y_dev, criterion, n_estimators_list)\n",
    "        df_RF[criterion+\"_f1\"], df_RF[criterion+\"_rmse\"], df_RF[criterion+\"_acc\"], df_RF[criterion+\"_hamm\"]= RF_model(train_data, Y_train, dev_data, Y_dev, \n",
    "                                                                   criterion, n_estimators_list)\n",
    "\n",
    "    print(df_RF)\n",
    "    print(\"df_RF\")\n",
    "    return(df_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaB_model(train_data, train_labels, dev_data, dev_labels, algorithm, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse=[]\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        AdaB_model = AdaBoostClassifier(n_estimators=n_estimators,algorithm=algorithm, learning_rate=1.2)\n",
    "        AdaB_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, AdaB_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, AdaB_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, AdaB_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, AdaB_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def AdaB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_AdaB =pd.DataFrame()\n",
    "    algorithm_list = [\"SAMME\", \"SAMME.R\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_AdaB[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_AdaB[algorithm+\"_f1\"], df_AdaB[algorithm+\"_rmse\"], df_AdaB[algorithm+\"_acc\"], df_AdaB[algorithm+\"_hamm\"]= AdaB_model(train_data, Y_train, \n",
    "                                                                         dev_data, Y_dev, algorithm, n_estimators_list)\n",
    "\n",
    "    print(df_AdaB)\n",
    "    print(\"df_AdaB\")\n",
    "    return(df_AdaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(train_data, train_labels, dev_data, dev_labels, kernel, c_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    for c in c_list:\n",
    "        if kernel == \"LinearSVC\":\n",
    "            svm_model = svm.LinearSVC(C=c, max_iter=10000)\n",
    "        elif kernel == \"poly\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, degree=2, gamma=1)\n",
    "        elif kernel == \"rbf\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, gamma=0.7)\n",
    "        else:\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c,)\n",
    "        \n",
    "        svm_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, svm_model.predict(dev_data), average=\"weighted\"))\n",
    "        rmse.append(metrics.mean_squared_error(dev_labels, svm_model.predict(dev_data), squared=False))\n",
    "        acc.append(metrics.accuracy_score(dev_labels, svm_model.predict(dev_data)))\n",
    "        hamm.append(metrics.hamming_loss(dev_labels, svm_model.predict(dev_data)))\n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "def SVM_models(train_data, Y_train, dev_data):\n",
    "    df_SVM =pd.DataFrame()\n",
    "    kernel_list = [\"linear\", \"rbf\", \"poly\", \"LinearSVC\"]\n",
    "    c_list = [0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 10, 20]\n",
    "    df_SVM[\"C\"] = c_list\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "        df_SVM[kernel+\"_f1\"], df_SVM[kernel+\"_rmse\"], df_SVM[kernel+\"_acc\"], df_SVM[kernel+\"_hamm\"] = SVM_model(train_data, Y_train, dev_data, Y_dev, kernel, c_list)\n",
    "    print(df_SVM)\n",
    "    print(\"df_SVM\")\n",
    "\n",
    "    return(df_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "**hidden_layer_sizestuple, length = n_layers - 2, default=(100,)**  \n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "**activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’**  \n",
    "Activation function for the hidden layer.  \n",
    "\n",
    "- ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x  \n",
    "- ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).  \n",
    "- ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).   \n",
    "- ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)  \n",
    "\n",
    "**solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’**  \n",
    "The solver for weight optimization.  \n",
    "\n",
    "- ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "- ‘sgd’ refers to stochastic gradient descent.\n",
    "- ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "\n",
    "Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "\n",
    "**alphafloat, default=0.0001**\n",
    "L2 penalty (regularization term) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(train_data, train_labels, dev_data, dev_labels, activation, solver_list, alpha_list, layer_list, choice):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse = []\n",
    "    acc = []\n",
    "    hamm = []\n",
    "    if choice == \"A\":\n",
    "        for alpha in alpha_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, activation=activation, alpha=alpha)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    elif choice == \"L\":\n",
    "        for layer in layer_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=layer, max_iter=1000, activation=activation)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    else:\n",
    "        for solver in solver_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=8000, activation=activation, solver=solver)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse.append(metrics.mean_squared_error(dev_labels, NN_model.predict(dev_data), squared=False))\n",
    "            acc.append(metrics.accuracy_score(dev_labels, NN_model.predict(dev_data)))\n",
    "            hamm.append(metrics.hamming_loss(dev_labels, NN_model.predict(dev_data)))\n",
    "    \n",
    "    return f1_score, rmse, acc, hamm\n",
    "\n",
    "#Note: Changing Alpha is not creating any variation in the f1_score.  Try first with L and then with S\n",
    "def NN_models(train_data, Y_train, dev_data, Y_dev, choice):\n",
    "    \n",
    "    df_NN =pd.DataFrame()\n",
    "    activation_list = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "    layer_list = [(10,10,10), (5,5,5), (3,3,3), (20, 20, 20)]\n",
    "    solver_list = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    alpha_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "    for activation in activation_list:\n",
    "        df_NN[activation+'_f1'], df_NN[activation+'_rmse'], df_NN[activation+'_acc'], df_NN[activation+'_hamm'] = NN_model(train_data, Y_train, dev_data, Y_dev, activation, solver_list, alpha_list, layer_list, choice)\n",
    "\n",
    "    if choice == \"A\":\n",
    "        df_NN[\"Alpha\"] = alpha_list\n",
    "    elif choice == \"L\":\n",
    "        df_NN[\"Layers\"] = layer_list\n",
    "    else:\n",
    "        df_NN[\"Solver\"] = solver_list\n",
    "    \n",
    "    print(df_NN)\n",
    "    print(\"df_NN\")\n",
    "    return(df_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_y(scale):\n",
    "    if scale == 2:\n",
    "        Y_train = train_y2\n",
    "        Y_dev = dev_y2\n",
    "    elif scale == 3:\n",
    "        Y_train = train_y3\n",
    "        Y_dev = dev_y3\n",
    "    elif scale == 4:\n",
    "        Y_train = train_y4\n",
    "        Y_dev = dev_y4\n",
    "    elif scale == 5:\n",
    "        Y_train = train_y5\n",
    "        Y_dev = dev_y5\n",
    "    elif scale == 10:\n",
    "        Y_train = train_y10\n",
    "        Y_dev = dev_y10\n",
    "    elif scale == 100:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    else:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    return(Y_train, Y_dev)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(Y_dev, Prediction, title):\n",
    "    cfm = confusion_matrix(Y_dev,Prediction)\n",
    "    if np.unique(Y_dev).max() > 5:\n",
    "        size = 6\n",
    "    else: \n",
    "        size = np.unique(Y_dev).max()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(cfm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cfm.shape[0]):\n",
    "        for j in range(cfm.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cfm[i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [2, 5, 10, 100]\n",
    "file_name = \"model_summary_baseline_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_NB = NB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_MNB = MNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_GNB = GNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_logR = LogR_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_DT = DT_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_RF = RF_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_SVM = SVM_models(train_data, Y_train, dev_data)\n",
    "    df_NN1 = NN_models(train_data, Y_train, dev_data, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data, Y_train, dev_data, Y_dev, \"S\")\n",
    "\n",
    "#     wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "#     wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "#     wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "#     wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "#     wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "#     wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "#     wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "#     wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "#     wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "#     wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "#     wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 7 components > IN ADDITION TO ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_pca = 7\n",
    "random_state = 0\n",
    "\n",
    "pca = PCA(n_components=components_pca, random_state=random_state)\n",
    "pca.fit(train_data)\n",
    "\n",
    "# overwriting train_data and dev_data to be the pca object - should do this in a cleaner way to preserve it but giving this a shot\n",
    "train_data1 = pca.transform(train_data)\n",
    "dev_data1 = pca.transform(dev_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [2, 3, 4, 5, 10, 100]\n",
    "file_name = \"model_summary_w_pca_7_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_NB = NB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_MNB = MNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_GNB = GNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_logR = LogR_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_DT = DT_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_RF = RF_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_SVM = SVM_models(train_data1, Y_train, dev_data1)\n",
    "    df_NN1 = NN_models(train_data1, Y_train, dev_data1, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data1, Y_train, dev_data1, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "#     wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "#     wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "#     wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 8 components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_pca = 8\n",
    "random_state = 0\n",
    "\n",
    "pca = PCA(n_components=components_pca, random_state=random_state)\n",
    "pca.fit(train_data)\n",
    "\n",
    "# overwriting train_data and dev_data to be the pca object - should do this in a cleaner way to preserve it but giving this a shot\n",
    "train_data2 = pca.transform(train_data)\n",
    "dev_data2 = pca.transform(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [2, 3, 4, 5, 10, 100]\n",
    "file_name = \"model_summary_w_pca_8_final.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "#     df_NB = NB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_MNB = MNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "#     df_GNB = GNB_models(train_data1, Y_train, dev_data1, Y_dev)\n",
    "    df_logR = LogR_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_DT = DT_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_RF = RF_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data2, Y_train, dev_data2, Y_dev)\n",
    "    df_SVM = SVM_models(train_data2, Y_train, dev_data2)\n",
    "    df_NN1 = NN_models(train_data2, Y_train, dev_data2, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data2, Y_train, dev_data2, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "#     wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "#     wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "#     wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
