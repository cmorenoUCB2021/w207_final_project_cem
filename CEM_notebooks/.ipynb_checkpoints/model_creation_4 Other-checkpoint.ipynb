{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "import xlsxwriter\n",
    "import openpyxl\n",
    "import os.path\n",
    "from os.path import exists\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "import imageio  \n",
    "import os\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>...</th>\n",
       "      <th>Palette_4_3</th>\n",
       "      <th>Palette_5_1</th>\n",
       "      <th>Palette_5_2</th>\n",
       "      <th>Palette_5_3</th>\n",
       "      <th>Avg_Color_1_1</th>\n",
       "      <th>Avg_Color_1_2</th>\n",
       "      <th>Avg_Color_1_3</th>\n",
       "      <th>Main_Palette_1_1</th>\n",
       "      <th>Main_Palette_1_2</th>\n",
       "      <th>Main_Palette_1_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 497 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                Id  Subject Focus  Eyes  Face  \\\n",
       "0           0  0007de18844b0dbbb5e1f607da0606e0              0     1     1   \n",
       "1           1  0009c66b9439883ba2750fb825e1d7db              0     1     1   \n",
       "2           2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1   \n",
       "3           3  0018df346ac9c1d8413cfcc888ca8246              0     1     1   \n",
       "4           4  001dc955e10590d3ca4673f034feeef2              0     0     0   \n",
       "\n",
       "   Near  Action  Accessory  Group  Collage  ...  Palette_4_3  Palette_5_1  \\\n",
       "0     1       0          0      1        0  ...     0.000002     0.000008   \n",
       "1     0       0          0      0        0  ...     0.000001     0.000004   \n",
       "2     1       0          0      0        0  ...     0.000005     0.000002   \n",
       "3     1       0          0      0        0  ...     0.000002     0.000009   \n",
       "4     1       0          0      1        0  ...     0.000004     0.000010   \n",
       "\n",
       "   Palette_5_2  Palette_5_3  Avg_Color_1_1  Avg_Color_1_2  Avg_Color_1_3  \\\n",
       "0     0.000008     0.000008       0.000009       0.000009       0.000009   \n",
       "1     0.000003     0.000002       0.000006       0.000006       0.000005   \n",
       "2     0.000007     0.000007       0.000006       0.000008       0.000007   \n",
       "3     0.000009     0.000008       0.000010       0.000009       0.000009   \n",
       "4     0.000010     0.000010       0.000008       0.000008       0.000007   \n",
       "\n",
       "   Main_Palette_1_1  Main_Palette_1_2  Main_Palette_1_3  \n",
       "0          0.000010          0.000010          0.000010  \n",
       "1          0.000004          0.000003          0.000002  \n",
       "2          0.000002          0.000007          0.000007  \n",
       "3          0.000010          0.000010          0.000010  \n",
       "4          0.000006          0.000005          0.000004  \n",
       "\n",
       "[5 rows x 497 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#UPLOAD CONSOLIDATED TABLE WITH FEATURES\n",
    "conso_filename = \"data_consolidated.csv\"\n",
    "directory = \"../data/\"\n",
    "df_data1 = pd.read_csv(directory+conso_filename)\n",
    "print(len(list(df_data1.columns)))\n",
    "df_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"train_augmented_reduced.csv\"\n",
    "df_augmented = pd.read_csv(\"../data/\"+filename)\n",
    "takeout1 = ['Unnamed: 0', 'Id','Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 'Group',\n",
    "            'Collage', 'Human', 'Occlusion', 'Info', 'Blur', 'Pawpularity',]\n",
    "dff1 = df_augmented.drop(takeout1, axis=1)\n",
    "dff1[\"id_max\"] = dff1.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Egyptian cat</td>\n",
       "      <td>1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tabby</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siamese cat</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labrador retriever</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tiger cat</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Persian cat</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kelpie</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dingo</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>malinois</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  count\n",
       "0        Egyptian cat   1824\n",
       "1               tabby    756\n",
       "2         Siamese cat    594\n",
       "3           Chihuahua    537\n",
       "4  Labrador retriever    473\n",
       "5           tiger cat    247\n",
       "6         Persian cat    212\n",
       "7              kelpie    201\n",
       "8               dingo    184\n",
       "9            malinois    169"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcount = pd.DataFrame(dff1[\"id_max\"].value_counts())\n",
    "fcount = fcount.reset_index()\n",
    "fcount.columns = [\"name\", \"count\"]\n",
    "fcount.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS USED TO CREATED DIFFERENT SCALES (1 TO 10, 1 TO 5, 1 TO 4, 1 TO 3, 1 TO 2)\n",
    "def scale10(n):\n",
    "    val = 0\n",
    "    if n <=10: \n",
    "        val = 1\n",
    "    elif n >10 and n<=20:\n",
    "        val = 2\n",
    "    elif n >20 and n <=30:\n",
    "        val = 3\n",
    "    elif n>30 and n <=40:\n",
    "        val = 4\n",
    "    elif n > 40 and n<=50:\n",
    "        val = 5\n",
    "    elif n>50 and n<=60:\n",
    "        val = 6\n",
    "    elif n>60 and n<=70:\n",
    "        val = 7\n",
    "    elif n>70 and n<=80:\n",
    "        val = 8\n",
    "    elif n>80 and n<=90:\n",
    "        val = 9\n",
    "    else: \n",
    "        val = 10\n",
    "    return(val)\n",
    "\n",
    "def scale5(n):\n",
    "    val = 0\n",
    "    if n <=20: \n",
    "        val = 1\n",
    "    elif n >20 and n<=40:\n",
    "        val = 2\n",
    "    elif n >40 and n <=60:\n",
    "        val = 3\n",
    "    elif n>60 and n <=80:\n",
    "        val = 4\n",
    "    else: val = 5\n",
    "\n",
    "    return(val)\n",
    "\n",
    "def scale4(n):\n",
    "    val = 0\n",
    "    if n <=25: \n",
    "        val = 1\n",
    "    elif n >25 and n<=50:\n",
    "        val = 2\n",
    "    elif n >50 and n <=75:\n",
    "        val = 3\n",
    "    else: \n",
    "        val = 4\n",
    "\n",
    "    return(val)\n",
    "\n",
    "def scale3(n):\n",
    "    val = 0\n",
    "    if n <=34: \n",
    "        val = 1\n",
    "    elif n >34 and n<=68:\n",
    "        val = 2\n",
    "    else:\n",
    "        val = 3\n",
    "\n",
    "    return(val)\n",
    "\n",
    "def scale2(n):\n",
    "    val = 0\n",
    "    if n <=50: \n",
    "        val = 1\n",
    "    else:\n",
    "        val = 2\n",
    "\n",
    "    return(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE COLUMNS WITH DIFFERENT SCALES FOR TESTING MODELS\n",
    "df_data[\"Scale10\"] = df_data.apply(lambda row: scale10(row.Pawpularity), axis=1)\n",
    "df_data[\"Scale5\"] = df_data.apply(lambda row: scale5(row.Pawpularity), axis=1)\n",
    "df_data[\"Scale4\"] = df_data.apply(lambda row: scale4(row.Pawpularity), axis=1)\n",
    "df_data[\"Scale3\"] = df_data.apply(lambda row: scale3(row.Pawpularity), axis=1)\n",
    "df_data[\"Scale2\"] = df_data.apply(lambda row: scale2(row.Pawpularity), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To select the SCALE you want to work with (10, 5, 4, 3, 2)\n",
    "def assign_y(scale):\n",
    "    if scale == 2:\n",
    "        Y_train = train_y2\n",
    "        Y_dev = dev_y2\n",
    "    elif scale == 3:\n",
    "        Y_train = train_y3\n",
    "        Y_dev = dev_y3\n",
    "    elif scale == 4:\n",
    "        Y_train = train_y4\n",
    "        Y_dev = dev_y4\n",
    "    elif scale == 5:\n",
    "        Y_train = train_y5\n",
    "        Y_dev = dev_y5\n",
    "    elif scale == 10:\n",
    "        Y_train = train_y10\n",
    "        Y_dev = dev_y10\n",
    "    elif scale == 100:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    else:\n",
    "        Y_train = train_labels\n",
    "        Y_dev = dev_labels\n",
    "    return(Y_train, Y_dev)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "Y_train, Y_dev = assign_y(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return list of mean for each range in scale\n",
    "def mean_scale(scale, Y_train, train_labels):\n",
    "    means = []\n",
    "    for i in range(1,scale+1):\n",
    "        index_to_get = np.where(Y_train == i)\n",
    "        me = train_labels[index_to_get].mean()\n",
    "        means.append(me)\n",
    "    return(means)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.209090909090909,\n",
       " 16.62266500622665,\n",
       " 25.88640510948905,\n",
       " 35.063784923563524,\n",
       " 44.9256880733945,\n",
       " 55.180701754385964,\n",
       " 64.96816976127322,\n",
       " 74.79357798165138,\n",
       " 84.8409090909091,\n",
       " 98.44859813084112]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = mean_scale(scale, Y_train, train_labels)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(Y_train, scale):\n",
    "    counts = []\n",
    "    for i in range(1, scale+1):\n",
    "        counts.append(np.count_nonzero(Y_train == i))\n",
    "    return(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 62,\n",
       " 68,\n",
       " 25,\n",
       " 29,\n",
       " 22,\n",
       " 22,\n",
       " 29,\n",
       " 29,\n",
       " 27,\n",
       " 41,\n",
       " 53,\n",
       " 66,\n",
       " 46,\n",
       " 71,\n",
       " 66,\n",
       " 94,\n",
       " 128,\n",
       " 125,\n",
       " 134,\n",
       " 154,\n",
       " 193,\n",
       " 205,\n",
       " 201,\n",
       " 229,\n",
       " 241,\n",
       " 234,\n",
       " 244,\n",
       " 243,\n",
       " 252,\n",
       " 264,\n",
       " 240,\n",
       " 198,\n",
       " 197,\n",
       " 208,\n",
       " 192,\n",
       " 177,\n",
       " 152,\n",
       " 143,\n",
       " 147,\n",
       " 145,\n",
       " 155,\n",
       " 126,\n",
       " 95,\n",
       " 105,\n",
       " 99,\n",
       " 95,\n",
       " 107,\n",
       " 80,\n",
       " 81,\n",
       " 53,\n",
       " 56,\n",
       " 63,\n",
       " 56,\n",
       " 71,\n",
       " 47,\n",
       " 49,\n",
       " 50,\n",
       " 57,\n",
       " 48,\n",
       " 35,\n",
       " 48,\n",
       " 53,\n",
       " 41,\n",
       " 39,\n",
       " 42,\n",
       " 28,\n",
       " 24,\n",
       " 26,\n",
       " 25,\n",
       " 37,\n",
       " 25,\n",
       " 29,\n",
       " 22,\n",
       " 23,\n",
       " 19,\n",
       " 21,\n",
       " 20,\n",
       " 22,\n",
       " 16,\n",
       " 22,\n",
       " 13,\n",
       " 17,\n",
       " 14,\n",
       " 13,\n",
       " 8,\n",
       " 18,\n",
       " 19,\n",
       " 11,\n",
       " 7,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 225]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = get_counts(Y_train, 100)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_mean_scale(scale, Y_train, train_labels):\n",
    "    adj_mean = []\n",
    "    i = 0\n",
    "    mean = train_labels.mean()\n",
    "    counts = get_counts(Y_train, scale)\n",
    "    total = sum(counts)\n",
    "    for count in counts:\n",
    "        adjm = (mean * count) / total\n",
    "        adj_mean.append(adjm)\n",
    "    return(adj_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.126986128625504\n"
     ]
    }
   ],
   "source": [
    "a = adj_mean_scale(scale, Y_train, train_labels)\n",
    "print(sum(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return Prediction based on mean for range in scale\n",
    "def predict_scale(prediction, mean_scale):\n",
    "    predict_out = []\n",
    "    n = len(mean_scale)\n",
    "    for p in prediction:\n",
    "        predict_out.append(mean_scale[p-1])\n",
    "    return(predict_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(Y_dev, Prediction, title):\n",
    "    cfm = confusion_matrix(Y_dev,Prediction)\n",
    "    if np.unique(Y_dev).max() > 5:\n",
    "        size = 6\n",
    "    else: \n",
    "        size = np.unique(Y_dev).max()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(cfm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "    for i in range(cfm.shape[0]):\n",
    "        for j in range(cfm.shape[1]):\n",
    "            ax.text(x=j, y=i,s=cfm[i, j], va='center', ha='center', size='xx-large')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n"
     ]
    }
   ],
   "source": [
    "column_names = list(df_data.columns)\n",
    "to_take_out = ['Unnamed: 0', 'Id','image', 'Scale10', 'Scale5','Scale4','Scale3', 'Scale2','Pawpularity']\n",
    "#to_take_out = ['Unnamed: 0', 'Id','image','Pawpularity', 'id']\n",
    "\n",
    "coln1 = len(column_names) - 8\n",
    "coln2 = coln1 + 3\n",
    "\n",
    "palette_to_keep = column_names[coln1:coln2]\n",
    "\n",
    "coln1 = 2\n",
    "coln2 = coln1+12\n",
    "basic_features = column_names[coln1:coln2]\n",
    "\n",
    "sf_select = fcount[fcount['count'] >= 1]\n",
    "sf_selected = list(sf_select['name'])\n",
    "\n",
    "to_keep = basic_features + palette_to_keep + sf_selected\n",
    "#to_keep = sf_selected\n",
    "\n",
    "print(len(to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9912\n",
      "(7930, 375) (7930,) (7930,)\n",
      "(1883, 375) (1883,) (1883,)\n",
      "(99, 375) (99,) (99,)\n",
      "(99,) (1883,) (7930,)\n",
      "(99,) (1883,) (7930,)\n",
      "(99,) (1883,) (7930,)\n",
      "(99,) (1883,) (7930,)\n",
      "(99,) (1883,) (7930,)\n"
     ]
    }
   ],
   "source": [
    "#Get X and Y data - shuffle data.\n",
    "X = np.array(df_data[to_keep])\n",
    "\n",
    "#Use to take out columns\n",
    "#X = np.array(df_data.drop(to_take_out, axis=1))\n",
    "\n",
    "Y = df_data['Pawpularity'].values[:]\n",
    "\n",
    "id_image = df_data['Id'].values[:]\n",
    "\n",
    "Y10 = df_data['Scale10'].values[:]\n",
    "Y5 = df_data['Scale5'].values[:]\n",
    "Y4 = df_data['Scale4'].values[:]\n",
    "Y3 = df_data['Scale3'].values[:]\n",
    "Y2 = df_data['Scale2'].values[:]\n",
    "\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y, id_image = X[shuffle], Y[shuffle], id_image[shuffle]\n",
    "Y10, Y5, Y4, Y3, Y2 = Y10[shuffle], Y5[shuffle], Y4[shuffle], Y3[shuffle], Y2[shuffle]\n",
    "\n",
    "# Define sizes for train, development and test data (0.5, 0.2, 0.3)\n",
    "per_train = 0.8\n",
    "per_dev = 0.19\n",
    "\n",
    "num_images = len(Y)\n",
    "train_size = int(round(num_images * per_train,0))\n",
    "dev_size = int(round(num_images * per_dev,0))\n",
    "\n",
    "# Split data based on defined sizes\n",
    "test_data, test_labels, id_test = X[train_size+dev_size:], Y[train_size+dev_size:], id_image[train_size+dev_size:]\n",
    "test_y10 = Y10[train_size+dev_size:]\n",
    "test_y5 = Y5[train_size+dev_size:]\n",
    "test_y4 = Y4[train_size+dev_size:]\n",
    "test_y3 = Y3[train_size+dev_size:]\n",
    "test_y2 = Y2[train_size+dev_size:]\n",
    "\n",
    "dev_data, dev_labels, id_dev = X[train_size:train_size+dev_size], Y[train_size:train_size+dev_size], id_image[train_size:train_size+dev_size]\n",
    "dev_y10 = Y10[train_size:train_size+dev_size]\n",
    "dev_y5 = Y5[train_size:train_size+dev_size]\n",
    "dev_y4 = Y4[train_size:train_size+dev_size]\n",
    "dev_y3 = Y3[train_size:train_size+dev_size]\n",
    "dev_y2 = Y2[train_size:train_size+dev_size]\n",
    "\n",
    "train_data, train_labels, id_train = X[:train_size], Y[:train_size], id_image[:train_size]\n",
    "train_y10 =  Y10[:train_size]\n",
    "train_y5 =  Y5[:train_size]\n",
    "train_y4 =  Y4[:train_size]\n",
    "train_y3 =  Y3[:train_size]\n",
    "train_y2 =  Y2[:train_size]\n",
    "\n",
    "print(num_images)\n",
    "print(train_data.shape, train_labels.shape, id_train.shape)\n",
    "print(dev_data.shape, dev_labels.shape, id_dev.shape)\n",
    "print(test_data.shape, test_labels.shape, id_test.shape)\n",
    "print(test_y10.shape, dev_y10.shape, train_y10.shape)\n",
    "print(test_y5.shape, dev_y5.shape, train_y5.shape)\n",
    "print(test_y4.shape, dev_y4.shape, train_y4.shape)\n",
    "print(test_y3.shape, dev_y3.shape, train_y3.shape)\n",
    "print(test_y2.shape, dev_y2.shape, train_y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Accuracy Score - RMSE when prediction is the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.48274030801912\n",
      "(1883,)\n",
      "20.8215770710572\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "avg_dev = Y_dev.mean()\n",
    "print(avg_dev)\n",
    "print(Y_dev.shape)\n",
    "\n",
    "basic_prediction = np.repeat(avg_dev, Y_dev.shape[0])\n",
    "rmse = np.sqrt(mean_squared_error(basic_prediction, Y_dev))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "k = 9\n",
    "means = mean_scale(scale, Y_train, train_labels)\n",
    "print(means)\n",
    "#means[0] = avg_dev\n",
    "#print(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [6.38470144328445, 21.0134891852569, 36.4396184947401, 35.0637849235635, 42.3183823993714, 48.7814289135307, 55.9382888698538, 62.3725506718493, 69.3185306046605, 87.0800899096906]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K:  9 ,for scale  100 , f1_score:  0.02849005077527504\n",
      "For K:  9 ,for scale  100 , MSME:  28.782259833916893\n"
     ]
    }
   ],
   "source": [
    "metric_list = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis']\n",
    "metric = metric_list[1]\n",
    "\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "algorithm_list = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "knn_mod = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm_list[0], weights=weights[0],  metric = metric)\n",
    "knn_mod.fit(train_data, Y_train)\n",
    "pred_knn = knn_mod.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, pred_knn, average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(pred_knn, Y_dev))\n",
    "\n",
    "print(\"For K: \",k,\",for scale \",scale,\", f1_score: \",f1_score)\n",
    "print(\"For K: \",k,\",for scale \",scale,\", MSME: \",rmse)\n",
    "\n",
    "#Generate and create dataframe of Confusion Matrix\n",
    "#print_confusion_matrix(Y_dev, pred_knn, \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.129337539432177,\n",
       " 16.586165048543688,\n",
       " 25.850182149362478,\n",
       " 34.96871741397289,\n",
       " 44.947610294117645,\n",
       " 55.36545454545455,\n",
       " 64.91135734072022,\n",
       " 74.94017094017094,\n",
       " 85.03521126760563,\n",
       " 98.6]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K:  9 ,for scale  100 , MSME:  28.782259833916893\n"
     ]
    }
   ],
   "source": [
    "pre_scale = predict_scale(pred_knn, means)\n",
    "rmse = np.sqrt(mean_squared_error(pre_scale, Y_dev))\n",
    "print(\"For K: \",k,\",for scale \",scale,\", MSME: \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.568818514007308 2 16.568818514007308\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "print(pre_scale[i], pred_knn[i], means[pred_knn[i]-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(train_data, train_labels, dev_data, dev_labels, algorithm, weigth, klist):\n",
    "    \n",
    "    f1_score = []\n",
    "    \n",
    "    for k in klist:\n",
    "        knn_mod = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm, weights=weigth, p=1)\n",
    "        knn_mod.fit(train_data, train_labels)\n",
    "        acc = knn_mod.score(dev_data, dev_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, knn_mod.predict(dev_data), average=\"weighted\"))\n",
    "    \n",
    "    return(f1_score)\n",
    "    \n",
    "def knn_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_knn = pd.DataFrame()\n",
    "    klist = [1, 2, 3, 4, 5, 6, 7,8,9, 10, 11, 12, 13, 14, 15]\n",
    "    algorithm_list = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "    weights = [\"uniform\", \"distance\"]\n",
    "    df_knn[\"K\"] = klist\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_knn[algorithm] = knn_model(train_data, Y_train, dev_data, Y_dev, algorithm, weights[1], klist)\n",
    "    print(df_knn)\n",
    "    print(\"df_knn\")\n",
    "    return(df_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    for alpha in alpha_list:\n",
    "        NB_mod = BernoulliNB(alpha=alpha)\n",
    "        NB_mod.fit(train_data, train_labels)\n",
    "        acc = NB_mod.score(dev_data, dev_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, NB_mod.predict(dev_data), average=\"weighted\"))\n",
    "    return(f1_score)\n",
    "\n",
    "def NB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_NB = pd.DataFrame()\n",
    "    df_NB[\"Alpha\"] = alpha_list\n",
    "    df_NB[\"F1_score\"] = NB_model(train_data, Y_train, dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_NB)\n",
    "    print(\"df_NB\")\n",
    "    return(df_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNB_model(train_data, train_labels, dev_data, dev_labels, alpha_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    for alpha in alpha_list:\n",
    "        MNB_mod = MultinomialNB(alpha=alpha)\n",
    "        MNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, MNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "    \n",
    "    return(f1_score)\n",
    "\n",
    "def MNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_MNB = pd.DataFrame()\n",
    "    df_MNB[\"Alpha\"] = alpha_list\n",
    "    df_MNB[\"F1_score\"] = MNB_model(train_data, Y_train, dev_data, Y_dev, alpha_list)\n",
    "\n",
    "    print(df_MNB)\n",
    "    print(\"df_MNB\")\n",
    "    return(df_MNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GNB_model(train_data, train_labels, dev_data, dev_labels, smoothing_list):\n",
    "    \n",
    "    f1_score = []\n",
    "    for var_smoothing in smoothing_list:\n",
    "        GNB_mod = GaussianNB(var_smoothing=var_smoothing)\n",
    "        GNB_mod.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, GNB_mod.predict(dev_data), average=\"weighted\"))\n",
    "    \n",
    "    return(f1_score)\n",
    "\n",
    "def GNB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    smoothing_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "    df_GNB = pd.DataFrame()\n",
    "    df_GNB[\"Var Smooth\"] = smoothing_list\n",
    "    df_GNB[\"F1_score\"] = GNB_model(train_data, Y_train, dev_data, Y_dev, smoothing_list)\n",
    "\n",
    "    print(df_GNB)\n",
    "    print(\"df_GNB\")\n",
    "    return(df_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression\n",
    "Warning The choice of the algorithm depends on the penalty chosen: Supported penalties by solver:  \n",
    "- ‘newton-cg’ - [‘l2’, ‘none’]  \n",
    "- ‘lbfgs’ - [‘l2’, ‘none’]  \n",
    "- ‘liblinear’ - [‘l1’, ‘l2’]  \n",
    "- ‘sag’ - [‘l2’, ‘none’]  \n",
    "- ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, ‘none’]\n",
    "\n",
    "**max_iter was increased to 200, so it would converge**\n",
    "- max_iter int, default=100\n",
    "- Maximum number of iterations taken for the solvers to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogR_model(train_data, train_labels, dev_data, dev_labels, penalty, solver, c_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    for c in c_list:\n",
    "        logR_mod = LogisticRegression(C=c, solver=solver, multi_class=\"auto\", penalty=penalty, max_iter=200)\n",
    "        logR_mod.fit(train_data, train_labels)\n",
    "        acc = logR_mod.score(dev_data, dev_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, logR_mod.predict(dev_data), average=\"weighted\"))\n",
    "    return(f1_score)\n",
    "\n",
    "def LogR_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_logR =pd.DataFrame()\n",
    "    solver_list = [\"liblinear\", \"newton-cg\", \"sag\", \"lbfgs\"]\n",
    "    c_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "\n",
    "    df_logR[\"C\"] = c_list\n",
    "    for solver in solver_list:\n",
    "        df_logR[solver] = LogR_model(train_data, Y_train, dev_data, Y_dev, \"l2\", solver, c_list)\n",
    "\n",
    "    print(df_logR)\n",
    "    print(\"df_LogR\")\n",
    "    return(df_logR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_model(train_data, train_labels, dev_data, dev_labels, criterion, max_depth_list):\n",
    "    \n",
    "    \n",
    "    #c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "    \n",
    "    f1_score = []\n",
    "    for max_depth in max_depth_list:\n",
    "        dt_model = DecisionTreeClassifier(criterion=criterion, min_samples_split=10, max_depth=max_depth)\n",
    "        dt_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, dt_model.predict(dev_data), average=\"weighted\"))\n",
    "\n",
    "    return(f1_score)\n",
    "\n",
    "def DT_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_DT =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    max_depth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    df_DT[\"max_depth\"] = max_depth_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "        df_DT[criterion] = DT_model(train_data, Y_train, dev_data, Y_dev, criterion, max_depth_list)\n",
    "\n",
    "    print(df_DT)\n",
    "    print(\"df_DT\")\n",
    "    return(df_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(train_data, train_labels, dev_data, dev_labels, criterion, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        RF_model = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion, min_samples_split=10)\n",
    "        RF_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, RF_model.predict(dev_data), average=\"weighted\"))\n",
    "\n",
    "    return(f1_score)\n",
    "\n",
    "def RF_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_RF =pd.DataFrame()\n",
    "    criterion_list = [\"entropy\", \"gini\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_RF[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for criterion in criterion_list:\n",
    "        df_RF[criterion] = RF_model(train_data, Y_train, dev_data, Y_dev, criterion, n_estimators_list)\n",
    "\n",
    "    print(df_RF)\n",
    "    print(\"df_RF\")\n",
    "    return(df_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaB_model(train_data, train_labels, dev_data, dev_labels, algorithm, n_estimators_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    for n_estimators in n_estimators_list:\n",
    "        AdaB_model = AdaBoostClassifier(n_estimators=n_estimators,algorithm=algorithm, learning_rate=1.2)\n",
    "        AdaB_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, AdaB_model.predict(dev_data), average=\"weighted\"))\n",
    "\n",
    "    return(f1_score)\n",
    "\n",
    "def AdaB_models(train_data, Y_train, dev_data, Y_dev):\n",
    "    df_AdaB =pd.DataFrame()\n",
    "    algorithm_list = [\"SAMME\", \"SAMME.R\"]\n",
    "    n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "    df_AdaB[\"n_estimators\"] = n_estimators_list\n",
    "\n",
    "    for algorithm in algorithm_list:\n",
    "        df_AdaB[algorithm] = AdaB_model(train_data, Y_train, dev_data, Y_dev, algorithm, n_estimators_list)\n",
    "\n",
    "    print(df_AdaB)\n",
    "    print(\"df_AdaB\")\n",
    "    return(df_AdaB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(train_data, train_labels, dev_data, dev_labels, kernel, c_list):\n",
    "        \n",
    "    f1_score = []\n",
    "    \n",
    "    for c in c_list:\n",
    "        if kernel == \"LinearSVC\":\n",
    "            svm_model = svm.LinearSVC(C=c, max_iter=10000)\n",
    "        elif kernel == \"poly\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, degree=2, gamma=1)\n",
    "        elif kernel == \"rbf\":\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c, gamma=0.7)\n",
    "        else:\n",
    "            svm_model = svm.SVC(kernel=kernel, C=c,)\n",
    "        \n",
    "        svm_model.fit(train_data, train_labels)\n",
    "        f1_score.append(metrics.f1_score(dev_labels, svm_model.predict(dev_data), average=\"weighted\"))\n",
    "\n",
    "    return(f1_score)\n",
    "\n",
    "def SVM_models(train_data, Y_train, dev_data):\n",
    "    df_SVM =pd.DataFrame()\n",
    "    kernel_list = [\"linear\", \"rbf\", \"poly\", \"LinearSVC\"]\n",
    "    c_list = [0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 10, 20]\n",
    "    df_SVM[\"C\"] = c_list\n",
    "\n",
    "    for kernel in kernel_list:\n",
    "        df_SVM[kernel] = SVM_model(train_data, Y_train, dev_data, Y_dev, kernel, c_list)\n",
    "    print(df_SVM)\n",
    "    print(\"df_SVM\")\n",
    "\n",
    "    return(df_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "**hidden_layer_sizestuple, length = n_layers - 2, default=(100,)**  \n",
    "The ith element represents the number of neurons in the ith hidden layer.\n",
    "\n",
    "**activation{‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’**  \n",
    "Activation function for the hidden layer.  \n",
    "\n",
    "- ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x  \n",
    "- ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).  \n",
    "- ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).   \n",
    "- ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)  \n",
    "\n",
    "**solver{‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’**  \n",
    "The solver for weight optimization.  \n",
    "\n",
    "- ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "- ‘sgd’ refers to stochastic gradient descent.\n",
    "- ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "\n",
    "Note: The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "\n",
    "**alphafloat, default=0.0001**\n",
    "L2 penalty (regularization term) parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(train_data, train_labels, dev_data, dev_labels, activation, solver_list, alpha_list, layer_list, choice):\n",
    "        \n",
    "    f1_score = []\n",
    "    \n",
    "    if choice == \"A\":\n",
    "        for alpha in alpha_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, activation=activation, alpha=alpha)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "    elif choice == \"L\":\n",
    "        for layer in layer_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=layer, max_iter=1000, activation=activation)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))    \n",
    "    else:\n",
    "        for solver in solver_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=8000, activation=activation, solver=solver)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "                \n",
    "    return(f1_score)\n",
    "\n",
    "#Note: Changing Alpha is not creating any variation in the f1_score.  Try first with L and then with S\n",
    "def NN_models(train_data, Y_train, dev_data, Y_dev, choice):\n",
    "    \n",
    "    df_NN =pd.DataFrame()\n",
    "    activation_list = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "    layer_list = [(10,10,10), (5,5,5), (3,3,3), (20, 20, 20)]\n",
    "    solver_list = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    alpha_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "    for activation in activation_list:\n",
    "        df_NN[activation] = NN_model(train_data, Y_train, dev_data, Y_dev, activation, solver_list, alpha_list, layer_list, choice)\n",
    "\n",
    "    if choice == \"A\":\n",
    "        df_NN[\"Alpha\"] = alpha_list\n",
    "    elif choice == \"L\":\n",
    "        df_NN[\"Layers\"] = layer_list\n",
    "    else:\n",
    "        df_NN[\"Solver\"] = solver_list\n",
    "    \n",
    "    print(df_NN)\n",
    "    print(\"df_NN\")\n",
    "    return(df_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [2, 3, 4, 5, 10, 100]\n",
    "file_name = \"model_summary.xlsx\"\n",
    "for scale in scale_list:\n",
    "    print(scale)\n",
    "    Y_train, Y_dev = assign_y(scale)\n",
    "    df_knn = knn_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_NB = NB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_MNB = MNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_GNB = GNB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_logR = LogR_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_DT = DT_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_RF = RF_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_AdaB = AdaB_models(train_data, Y_train, dev_data, Y_dev)\n",
    "    df_SVM = SVM_models(train_data, Y_train, dev_data)\n",
    "    df_NN1 = NN_models(train_data, Y_train, dev_data, Y_dev, \"L\")\n",
    "    df_NN2 = NN_models(train_data, Y_train, dev_data, Y_dev, \"S\")\n",
    "\n",
    "    wrt_excel(file_name, \"knn-\"+str(scale), df_knn)\n",
    "    wrt_excel(file_name, \"NB-\"+str(scale), df_NB)    \n",
    "    wrt_excel(file_name, \"MNB-\"+str(scale), df_MNB)\n",
    "    wrt_excel(file_name, \"GNB-\"+str(scale), df_GNB)\n",
    "    wrt_excel(file_name, \"logR-\"+str(scale), df_logR)\n",
    "    wrt_excel(file_name, \"DT-\"+str(scale), df_DT)\n",
    "    wrt_excel(file_name, \"RF-\"+str(scale), df_RF)\n",
    "    wrt_excel(file_name, \"AdaB-\"+str(scale), df_AdaB)\n",
    "    wrt_excel(file_name, \"SVM-\"+str(scale), df_SVM)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"L\", df_NN1)\n",
    "    wrt_excel(file_name, \"NN-\"+str(scale)+\"S\", df_NN2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Model Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = knn_models(train_data, Y_train, dev_data, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Exploring KDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN a single model: Options\n",
    "**n_neighbors:**  integer, default=5\n",
    "\n",
    "**weights: {‘uniform’, ‘distance’} or callable, default=’uniform’. Weight function used in prediction. Possible values**:    \n",
    "(a) ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.  \n",
    "(b) ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.  \n",
    "(b) [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.  \n",
    "\n",
    "**algorithm{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’**\n",
    "Algorithm used to compute the nearest neighbors:\n",
    "(a) ‘ball_tree’ will use BallTree  \n",
    "(b) ‘kd_tree’ will use KDTree  \n",
    "(c) ‘brute’ will use a brute-force search.  \n",
    "(d) ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.  \n",
    "\n",
    "**metric - str or callable, default=’minkowski’**  \n",
    "“euclidean”, “manhattan”, “chebyshev”, “minkowski”, “wminkowski”, “seuclidean”, “mahalanobis”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For K:  9 ,for scale  100 , f1_score:  0.014397838307718295\n",
      "For K:  9 ,for scale  100 , MSME:  29.785612083710394\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "k = 9\n",
    "\n",
    "metric_list = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'wminkowski', 'seuclidean', 'mahalanobis']\n",
    "metric = metric_list[1]\n",
    "\n",
    "weights = [\"uniform\", \"distance\"]\n",
    "algorithm_list = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "\n",
    "knn_mod = KNeighborsClassifier(n_neighbors=k, algorithm=algorithm_list[0], weights=weights[0],  metric = metric)\n",
    "knn_mod.fit(train_data, Y_train)\n",
    "pred_knn = knn_mod.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, knn_mod.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(knn_mod.predict(dev_data), Y_dev))\n",
    "\n",
    "print(\"For K: \",k,\",for scale \",scale,\", f1_score: \",f1_score)\n",
    "print(\"For K: \",k,\",for scale \",scale,\", MSME: \",rmse)\n",
    "\n",
    "#Generate and create dataframe of Confusion Matrix\n",
    "#print_confusion_matrix(Y_dev, pred_knn, \"KNN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli - For alpha:  0.01 ,for scale  100 , f1_score:  0.011804179791479855\n",
      "Bernoulli - For alpha:  0.01 ,for scale  100 , RMSE:  23.059794356687206\n",
      "GNB - For alpha:  0.01 ,for scale  100 , f1_score:  0.0\n",
      "GNB - For alpha:  0.01 ,for scale  100 , RMSE:  49.77909245528488\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "\n",
    "alpha_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "smoothing_list = [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "i = 3\n",
    "\n",
    "NB_mod = BernoulliNB(alpha=alpha_list[i])\n",
    "NB_mod.fit(train_data, Y_train)\n",
    "pred_NB = NB_mod.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, NB_mod.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(NB_mod.predict(dev_data), Y_dev))\n",
    "\n",
    "print(\"Bernoulli - For alpha: \",alpha_list[i],\",for scale \",scale,\", f1_score: \",f1_score)\n",
    "print(\"Bernoulli - For alpha: \",alpha_list[i],\",for scale \",scale,\", RMSE: \",rmse)\n",
    "#print_confusion_matrix(Y_dev, pred_NB, \"NB\")\n",
    "\n",
    "# MNB_mod = MultinomialNB(alpha=alpha_list[i])\n",
    "# MNB_mod.fit(train_data, Y_train)\n",
    "# pred_MNB = MNB_mod.predict(dev_data)\n",
    "# f1_score = metrics.f1_score(Y_dev, MNB_mod.predict(dev_data), average=\"weighted\")\n",
    "# rmse = np.sqrt(mean_squared_error(MNB_mod.predict(dev_data), Y_dev))\n",
    "\n",
    "# print(\"MNB - For alpha: \",alpha_list[i],\",for scale \",scale,\", f1_score: \",f1_score)\n",
    "# print(\"MNB - For alpha: \",alpha_list[i],\",for scale \",scale,\", RMSE: \",rmse)\n",
    "# print_confusion_matrix(Y_dev, pred_MNB, \"MNB\")\n",
    "\n",
    "GNB_mod = GaussianNB(var_smoothing=smoothing_list[i])\n",
    "GNB_mod.fit(train_data, Y_train)\n",
    "pred_GNB = GNB_mod.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, GNB_mod.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(GNB_mod.predict(dev_data), Y_dev))\n",
    "\n",
    "print(\"GNB - For alpha: \",alpha_list[i],\",for scale \",scale,\", f1_score: \",f1_score)\n",
    "print(\"GNB - For alpha: \",alpha_list[i],\",for scale \",scale,\", RMSE: \",rmse)\n",
    "\n",
    "#print_confusion_matrix(Y_dev, pred_GNB, \"GNB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "**multi_class{‘auto’, ‘ovr’, ‘multinomial’}, default=’auto’**  \n",
    "If the option chosen is ‘ovr’, then a binary problem is fit for each label. For ‘multinomial’ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. ‘multinomial’ is unavailable when solver=’liblinear’. ‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score:  0.019405644192027574\n",
      "RMSE:  25.78602873162663\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "c_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 100]\n",
    "solver_list = [\"liblinear\", \"newton-cg\", \"sag\", \"lbfgs\"]\n",
    "c_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "penalty = [\"l1\", \"l2\"]\n",
    "\n",
    "logR_mod = LogisticRegression(C=c_list[8], solver=solver_list[2], multi_class='multinomial', penalty=penalty[1], max_iter=200)\n",
    "logR_mod.fit(train_data, Y_train)\n",
    "pred_logR = logR_mod.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, logR_mod.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(logR_mod.predict(dev_data), Y_dev))\n",
    "\n",
    "print(\"F1_score: \", f1_score)\n",
    "print(\"RMSE: \", rmse)\n",
    "#print_confusion_matrix(Y_dev, pred_logR, \"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion Tress - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score Decision Tree:  0.01841708408398719\n",
      "RMSE Decision Tree:  50.8510889246444\n",
      "F1_score Random Forest:  0.02079746977604736\n",
      "RMSE Random Forest:  27.36241107972015\n",
      "F1_score AdaBoost:  0.005339129374253928\n",
      "RMSE AdaBoost:  23.345860633300845\n"
     ]
    }
   ],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "criterion_list = [\"entropy\", \"gini\"]\n",
    "max_depth_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "n_estimators_list = [5, 10, 15, 20, 25, 30]\n",
    "algorithm_list = [\"SAMME\", \"SAMME.R\"]\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion=criterion_list[0], min_samples_split=10, max_depth=max_depth_list[5])\n",
    "dt_model.fit(train_data, Y_train)\n",
    "pred_dt = dt_model.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, dt_model.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(dt_model.predict(dev_data), Y_dev))\n",
    "print(\"F1_score Decision Tree: \", f1_score)\n",
    "print(\"RMSE Decision Tree: \", rmse)\n",
    "#print_confusion_matrix(Y_dev, pred_dt, \"Decision Tree\")\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators=n_estimators_list[3],criterion=criterion_list[0], min_samples_split=10)\n",
    "RF_model.fit(train_data, Y_train)\n",
    "pred_RF = RF_model.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, RF_model.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(RF_model.predict(dev_data), Y_dev))\n",
    "print(\"F1_score Random Forest: \", f1_score)\n",
    "print(\"RMSE Random Forest: \", rmse)\n",
    "#print_confusion_matrix(Y_dev, pred_RF, \"Random Forest\")\n",
    "\n",
    "AdaB_model = AdaBoostClassifier(n_estimators=n_estimators_list[3],algorithm=algorithm_list[0], learning_rate=1.2)\n",
    "AdaB_model.fit(train_data, Y_train)\n",
    "pred_AdaB = AdaB_model.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, AdaB_model.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(AdaB_model.predict(dev_data), Y_dev))\n",
    "print(\"F1_score AdaBoost: \", f1_score)\n",
    "print(\"RMSE AdaBoost: \", rmse)\n",
    "#print_confusion_matrix(Y_dev, pred_AdaB, \"Ada Boooster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 10\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "kernel_list = [\"linear\", \"rbf\", \"poly\", \"LinearSVC\"]\n",
    "c_list = [0.5, 1, 1.5, 2, 2.5, 3, 4, 5, 10, 20]\n",
    "\n",
    "svm_LSVC = svm.LinearSVC(C=c_list[5], max_iter=10000)\n",
    "svm_LSVC.fit(train_data, Y_train)\n",
    "pred_LSVC = svm_LSVC.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, svm_LSVC.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(svm_LSVC.predict(dev_data), Y_dev))\n",
    "print(\"F1_score LinearSVC: \", f1_score)\n",
    "print(\"RMSE LinearSVC: \", rmse)\n",
    "print_confusion_matrix(Y_dev, pred_LSVC, \"SVM LinearSVC\")\n",
    "\n",
    "svm_poly = svm.SVC(kernel=\"poly\", C=c_list[5], degree=2, gamma=1)\n",
    "svm_poly.fit(train_data, Y_train)\n",
    "pred_poly = svm_poly.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, svm_poly.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(svm_poly.predict(dev_data), Y_dev))\n",
    "print(\"F1_score SVC poly: \", f1_score)\n",
    "print(\"RMSE SVC poly: \", rmse)\n",
    "print_confusion_matrix(Y_dev, pred_poly, \"SVM Poly\")\n",
    "\n",
    "svm_rbf = svm.SVC(kernel=\"rbf\", C=c_list[5], gamma=0.7)\n",
    "svm_rbf.fit(train_data, Y_train)\n",
    "pred_rbf = svm_rbf.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, svm_rbf.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(svm_rbf.predict(dev_data), Y_dev))\n",
    "print(\"F1_score SVC rbf: \", f1_score)\n",
    "print(\"RMSE SVC rbf: \", rmse)\n",
    "print_confusion_matrix(Y_dev, pred_rbf, \"SVM rbf\")\n",
    "\n",
    "svm_lin = svm.SVC(kernel=\"linear\", C=c_list[5])\n",
    "svm_lin.fit(train_data, Y_train)\n",
    "pred_lin = svm_lin.predict(dev_data)\n",
    "f1_score = metrics.f1_score(Y_dev, svm_lin.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(svm_lin.predict(dev_data), Y_dev))\n",
    "print(\"F1_score SVD linear: \", f1_score)\n",
    "print(\"RMSE SVD linear: \", rmse)\n",
    "print_confusion_matrix(Y_dev, pred_lin, \"SVM linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model1(train_data, train_labels, dev_data, dev_labels, activation, solver_list, alpha_list, layer_list, choice):\n",
    "        \n",
    "    f1_score = []\n",
    "    rmse_score = []\n",
    "    \n",
    "    if choice == \"A\":\n",
    "        for alpha in alpha_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, activation=activation, alpha=alpha)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse_score.append( np.sqrt(mean_squared_error(NN_model.predict(dev_data), Y_dev)) )\n",
    "    elif choice == \"L\":\n",
    "        for layer in layer_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=layer, max_iter=1000, activation=activation)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))    \n",
    "            rmse_score.append( np.sqrt(mean_squared_error(NN_model.predict(dev_data), Y_dev)) )\n",
    "    else:\n",
    "        for solver in solver_list:\n",
    "            NN_model = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=8000, activation=activation, solver=solver)\n",
    "            NN_model.fit(train_data, train_labels)\n",
    "            f1_score.append(metrics.f1_score(dev_labels, NN_model.predict(dev_data), average=\"weighted\"))\n",
    "            rmse_score.append( np.sqrt(mean_squared_error(NN_model.predict(dev_data), Y_dev)) )\n",
    "                \n",
    "    return(f1_score, rmse_score)\n",
    "\n",
    "#Note: Changing Alpha is not creating any variation in the f1_score.  Try first with L and then with S\n",
    "def NN_models1(train_data, Y_train, dev_data, Y_dev, choice):\n",
    "    \n",
    "    df_NN =pd.DataFrame()\n",
    "    #activation_list = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "    #layer_list = [(10,10,10), (5,5,5), (3,3,3), (20, 20, 20)]\n",
    "    #solver_list = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "    #alpha_list = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "    activation_list = [\"identity\"]\n",
    "    layer_list = [(10,10,10)]\n",
    "    solver_list = [\"lbfgs\"]\n",
    "    alpha_list = [0.0001]\n",
    "\n",
    "    for activation in activation_list:\n",
    "        f1 , rmse = NN_model1(train_data, Y_train, dev_data, Y_dev, activation, solver_list, alpha_list, layer_list, choice)\n",
    "        df_NN[activation+\"-\"+\"f1\"] = f1 \n",
    "        df_NN[activation+\"-\"+\"RMSE\"] = rmse \n",
    "\n",
    "    if choice == \"A\":\n",
    "        df_NN[\"Alpha\"] = alpha_list\n",
    "    elif choice == \"L\":\n",
    "        df_NN[\"Layers\"] = layer_list\n",
    "    else:\n",
    "        df_NN[\"Solver\"] = solver_list\n",
    "    \n",
    "    print(df_NN)\n",
    "    print(\"df_NN\")\n",
    "    return(df_NN)\n",
    "\n",
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "\n",
    "df_NN1 = NN_models1(train_data, Y_train, dev_data, Y_dev, \"L\")\n",
    "df_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE NEURAL NETWORK\n",
    "scale = 100\n",
    "layer_list = [(10,10,10), (5,5,5), (3,3,3), (20, 20, 20), (1000,1000,1000)]\n",
    "activation_list = [\"identity\", \"logistic\", \"tanh\", \"relu\"]\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "\n",
    "NN_model = MLPClassifier(hidden_layer_sizes=layer_list[4], max_iter=1000, activation=activation_list[3])\n",
    "NN_model.fit(train_data, Y_train)\n",
    "f1_score = metrics.f1_score(Y_dev, NN_model.predict(dev_data), average=\"weighted\")\n",
    "rmse = np.sqrt(mean_squared_error(NN_model.predict(dev_data), Y_dev))\n",
    "\n",
    "print(\"F1-score: \",f1_score)\n",
    "print(\"RMSE: \",rmse)\n",
    "#print_confusion_matrix(Y_dev, NN_model.predict(dev_data), \"Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras - Tensorflow\n",
    "\n",
    "- For X values: using StandardScaler ->  X_scaler = StandardScaler().fit(traind_data):  \n",
    "> train_data -> X_train_scaled  \n",
    "> dev_data => X_test_scaled  \n",
    "\n",
    "- For Y values: usig label_encoder.transform(Y_train):\n",
    "> Y_train -> encoded_y_train  \n",
    "> Y_dev -> encoded_y_dev  \n",
    "\n",
    "- Then convert to one-hot-encoding:\n",
    "> y_train_categorical = to_catergorical(encoded_y_train)  \n",
    "> y_test_categorical = to_categorical(encoded_y_dev)  \n",
    "\n",
    "**Useful References:**  \n",
    "- https://towardsdatascience.com/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3#:~:text=Sequential%20Model%20is%20the%20easiest%20way%20to%20get,implement%20our%20own%20custom%20forward-pass%20of%20the%20model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#For saving and loading created models and labelencoders\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "\n",
    "#For CREATING NEURAL NETWORK MODEL\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    #val_metrics = history.history['val_'+metric]\n",
    "    val_metrics = history.history[metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 100\n",
    "Y_train, Y_dev = assign_y(scale)\n",
    "\n",
    "# Step 0: SCALE THE DATA - TO BRING THEM TO THE SAME SCALE (MAY NOT BE NEEDED HERE AS IT IS ZEROS AND ONES)\n",
    "X_scaler = StandardScaler().fit(train_data)\n",
    "X_train_scaled = X_scaler.transform(train_data)\n",
    "X_test_scaled = X_scaler.transform(dev_data)\n",
    "#print(X_test_scaled)\n",
    "\n",
    "# Step 1: Label-encode data set (NOT NEEDED AS Y IS ALREADY CODED AS NUMERIC)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y_train)\n",
    "\n",
    "encoded_y_train = label_encoder.transform(Y_train)\n",
    "encoded_y_dev = label_encoder.transform(Y_dev)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(Y_train)\n",
    "y_test_categorical = to_categorical(Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the label_encoder - When using encoded, it could be saved for being uploaded later for use with model\n",
    "#from sklearn.externals.joblib import dump, load  - THIS DID NOT WORK - USED THE CODE BELOW\n",
    "\n",
    "dump(label_encoder, 'Project_1_NN_label_encoder.bin', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale = numer of output units (depending on scale being used)\n",
    "#input_dim = number of features being used for the model\n",
    "\n",
    "input_dim = len(X_test_scaled[0])\n",
    "print(input_dim)\n",
    "print(X_train_scaled.shape)\n",
    "print(scale)\n",
    "\n",
    "units = [200, 200]\n",
    "\n",
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=units[0], activation='relu', input_dim=input_dim))\n",
    "model.add(Dense(units=units[1], activation='relu'))\n",
    "model.add(Dense(units=scale+1, activation='softmax'))\n",
    "\n",
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled)\n",
    "print(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(Y_dev, encoded_predictions, \"Keras-Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"FP_NN_FDF1_scale_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Neural Network - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Convolutional Neural Networks in Keras for Time Sequences\n",
    "\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow.keras\n",
    "\n",
    "TIME_PERIODS = 1\n",
    "num_sensors = input_dim\n",
    "input_shape = input_dim\n",
    "num_classes = scale+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "model_m = Sequential()\n",
    "model_m.add(Reshape((TIME_PERIODS, num_sensors), input_shape=(input_shape,)))\n",
    "model_m.add(Conv1D(n, 1, activation='relu', input_shape=(TIME_PERIODS, num_sensors)))\n",
    "model_m.add(Conv1D(n, 1, activation='relu'))\n",
    "model_m.add(MaxPooling1D(1))\n",
    "model_m.add(Conv1D(n, 1, activation='relu'))\n",
    "model_m.add(Conv1D(n, 1, activation='relu'))\n",
    "model_m.add(GlobalAveragePooling1D())\n",
    "model_m.add(Dropout(0.5))\n",
    "model_m.add(Dense(num_classes, activation='softmax'))\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [keras.callbacks.ModelCheckpoint(filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "                                                  monitor='val_loss', save_best_only=True),\n",
    "                  keras.callbacks.EarlyStopping(monitor='acc', patience=1)]\n",
    "\n",
    "model_m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 50\n",
    "\n",
    "history = model_m.fit(X_train_scaled,\n",
    "                      y_train_categorical,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model_m.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_m.save(\"FP_1DCNN_FDF_scale_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w207",
   "language": "python",
   "name": "w207"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
